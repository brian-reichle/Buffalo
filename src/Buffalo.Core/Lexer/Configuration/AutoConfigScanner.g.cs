// <auto-generated />
//------------------------------------------------------------------------------
// This code is auto-generated.
// Do not attempt to edit this file by hand, you could hurt yourself!
//------------------------------------------------------------------------------

using System;
using System.Collections;
using System.Collections.Generic;
using System.Diagnostics;
using System.Threading;

namespace Buffalo.Core.Lexer.Configuration
{
	internal abstract class AutoConfigScanner<TToken> : IEnumerable<TToken>, IEnumerator<TToken>
		where TToken : class
	{
		public enum TokenType : ushort
		{
			EOF = 0,
			OpenBrace = 1,
			CloseBrace = 2,
			Semicolon = 3,
			Assign = 4,
			State = 5,
			Token = 6,
			Label = 7,
			String = 8,
			BrokenString = 9,
			Regex = 10,
			BrokenRegex = 11,
			Comment = 12,
			BrokenComment = 13,
			Whitespace = 14,
			Error = 15,
		}

		// [Statistics]
		// Char Classifications : 22
		// Char Ranges          : 43
		// States               : 29
		//   Terminal           : 8
		// Transition Table     : 370/638 (57.99%)
		//   Offsets            : 29
		//   Actions            : 341
		// Memory Footprint     : 970 bytes
		//   Boundries          : 86 bytes
		//   Classifications    : 86 bytes
		//   Transitions        : 740 bytes
		//   Token Types        : 58 bytes
		// Assembly Footprint   : 395 bytes (40.72%)
		protected AutoConfigScanner(string expressionString)
		{
			_cache = TableCache.Get();
			_charClassificationBoundries = _cache._charClassificationBoundries;
			_charClassification = _cache._charClassification;
			_transitionTable = _cache._transitionTable;
			_tokenTypes = _cache._tokenTypes;
			_expressionString = expressionString;
		}

		protected AutoConfigScanner(AutoConfigScanner<TToken> source)
		{
			_cache = source._cache;
			_charClassificationBoundries = source._charClassificationBoundries;
			_charClassification = source._charClassification;
			_transitionTable = source._transitionTable;
			_tokenTypes = source._tokenTypes;
			_expressionString = source._expressionString;
		}

		~AutoConfigScanner()
		{
			Dispose(false);
		}

		protected abstract TToken NewToken(TokenType type, string expressionString, int startPosition, int length);

		protected virtual AutoConfigScanner<TToken> NewScanner()
		{
			AutoConfigScanner<TToken> result = (AutoConfigScanner<TToken>)MemberwiseClone();
			result._solIndicies = new List<int>();
			result._currentToken = null;
			result._nextCharPosition = 0;
			return result;
		}

		protected void StartOfLine(int charIndex, out int lineNumber, out int charNumber)
		{
			int index = _solIndicies.BinarySearch(charIndex);
			index = index < 0 ? -2 - index : index;

			lineNumber = index + 2;
			charNumber = index < 0 ? charIndex + 1 : charIndex - _solIndicies[index] + 1;
		}

		static ushort[] Expand(string resourceName)
		{
			using (System.IO.Stream stream = System.Reflection.Assembly.GetExecutingAssembly().GetManifestResourceStream(resourceName))
			{
				const byte FOLLOW = 0x80;
				const byte REPEAT = 0x40;
				const byte FIRSTBODY = 0x3F;
				const byte SUBBODY = 0x7F;

				int value;
				byte tmp;

				tmp = unchecked((byte)stream.ReadByte());
				value = tmp & FIRSTBODY;

				while ((tmp & FOLLOW) != 0)
				{
					tmp = unchecked((byte)stream.ReadByte());
					value = (value << 7) | (tmp & SUBBODY);
				}

				int write = 0;
				ushort[] result = new ushort[value];

				while (stream.Position < stream.Length)
				{
					tmp = unchecked((byte)stream.ReadByte());
					if ((tmp & REPEAT) == 0)
					{
						value = tmp & FIRSTBODY;

						while ((tmp & FOLLOW) != 0)
						{
							tmp = unchecked((byte)stream.ReadByte());
							value = (value << 7) | (tmp & SUBBODY);
						}

						result[write++] = unchecked((ushort)value);
					}
					else
					{
						int count = tmp & FIRSTBODY;

						while ((tmp & FOLLOW) != 0)
						{
							tmp = unchecked((byte)stream.ReadByte());
							count = (count << 7) | (tmp & SUBBODY);
						}

						tmp = unchecked((byte)stream.ReadByte());
						value = tmp & FIRSTBODY;

						while ((tmp & FOLLOW) != 0)
						{
							tmp = unchecked((byte)stream.ReadByte());
							value = (value << 7) | (tmp & SUBBODY);
						}

						while (count > 0)
						{
							result[write++] = unchecked((ushort)value);
							count--;
						}
					}
				}

				return result;
			}
		}

		int ClassifyChar(char c)
		{
			int lowerBound = 0;
			int upperBound = _charClassificationBoundries.Length;

			while (lowerBound < upperBound)
			{
				int mid = (lowerBound + upperBound) >> 1;

				if (c <= _charClassificationBoundries[mid])
				{
					upperBound = mid;
				}
				else
				{
					lowerBound = mid + 1;
				}
			}

			return _charClassification[lowerBound];
		}

		#region IEnumerable<TToken> Members

		public IEnumerator<TToken> GetEnumerator()
		{
			if (Interlocked.Exchange(ref _started, 1) == 0)
			{
				return this;
			}
			else
			{
				return NewScanner();
			}
		}

		#endregion

		#region IEnumerable Members

		IEnumerator IEnumerable.GetEnumerator()
		{
			return GetEnumerator();
		}

		#endregion

		#region IEnumerator<TToken> Members

		TToken IEnumerator<TToken>.Current
		{
			[DebuggerStepThrough]
			get { return _currentToken; }
		}

		#endregion

		#region IDisposable Members

		void IDisposable.Dispose()
		{
			Dispose(true);
			GC.SuppressFinalize(this);
		}

		protected virtual void Dispose(bool isDisposing)
		{
		}

		#endregion

		#region IEnumerator Members

		object IEnumerator.Current
		{
			[DebuggerStepThrough]
			get { return _currentToken; }
		}

		bool IEnumerator.MoveNext()
		{
			do
			{
				if (_nextCharPosition > _expressionString.Length)
				{
					_currentToken = null;
					return false;
				}
				else if (_nextCharPosition == _expressionString.Length)
				{
					_currentToken = NewToken(TokenType.EOF, _expressionString, _expressionString.Length, 0);
					_nextCharPosition++;
				}
				else
				{
					int state = 0;
					int startOfNextToken = -1;
					TokenType type = TokenType.EOF;
					int lastSolIndex = _solIndicies.Count > 0 ? _solIndicies[_solIndicies.Count - 1] : 0;

					for (int i = _nextCharPosition; i < _expressionString.Length; i++)
					{
						if (i > lastSolIndex)
						{
							if (_expressionString[i] == '\n' ||
								(_expressionString[i] == '\r' && (i + 1 == _expressionString.Length || _expressionString[i + 1] != '\n')))
							{
								_solIndicies.Add(lastSolIndex = i + 1);
							}
						}

						int offset = _transitionTable[state];

						if (offset == 0 || (state = _transitionTable[offset + ClassifyChar(_expressionString[i])] - 1) == -1)
						{
							break;
						}
						else
						{
							TokenType newType = _tokenTypes[state];

							if (newType != TokenType.EOF)
							{
								type = newType;
								startOfNextToken = i + 1;
							}
						}
					}

					if (type != TokenType.EOF)
					{
						// if end is less than the last value of i then you will end up re-reading some characters,
						// if the start state is the only state that is not an end state then this will never happen.
						_currentToken = NewToken(type, _expressionString, _nextCharPosition, startOfNextToken - _nextCharPosition);
						_nextCharPosition = startOfNextToken;
					}
					else
					{
						// if you write your rules properly then this should never happen.
						// eg. add a rule at the end that matches a single instance of any character.
						throw new InvalidOperationException(string.Format("Got stuck at position {0}.", _nextCharPosition));
					}
				}
			}
			while (_currentToken == null);

			return true;
		}

		void IEnumerator.Reset()
		{
			_currentToken = null;
			_nextCharPosition = 0;
			_solIndicies.Clear();
		}

		#endregion

		[DebuggerBrowsable(DebuggerBrowsableState.Never)]
		TToken _currentToken;
		[DebuggerBrowsable(DebuggerBrowsableState.Never)]
		int _nextCharPosition;
		[DebuggerBrowsable(DebuggerBrowsableState.Never)]
		int _started;

		[DebuggerBrowsable(DebuggerBrowsableState.Never)]
		List<int> _solIndicies = new List<int>();
		[DebuggerBrowsable(DebuggerBrowsableState.Never)]
		readonly string _expressionString;

		[DebuggerBrowsable(DebuggerBrowsableState.Never)]
		readonly char[] _charClassificationBoundries;
		[DebuggerBrowsable(DebuggerBrowsableState.Never)]
		readonly ushort[] _charClassification;
		[DebuggerBrowsable(DebuggerBrowsableState.Never)]
		readonly ushort[] _transitionTable;
		[DebuggerBrowsable(DebuggerBrowsableState.Never)]
		readonly TokenType[] _tokenTypes;

		[DebuggerBrowsable(DebuggerBrowsableState.Never)]
		readonly TableCache _cache;

		class TableCache
		{
			protected TableCache()
			{
				_charClassificationBoundries = new char[42]
				{
					'\b', '\t', '\n', '\f', '\r', '\u001f', ' ', '!', '"', '#', '$', ')', '*', '.', '/', '9',
					':', ';', '<', '=', '@', 'Z', '[', '\\', ']', '^', '`', 'a', 'd', 'e', 'j', 'k',
					'm', 'n', 'o', 'r', 's', 't', 'z', '{', '|', '}',
				};
				_charClassification = new ushort[43]
				{
					17, 6, 0, 6, 0, 17, 6, 17, 1, 17, 4, 17, 5, 17, 16, 10,
					17, 2, 17, 19, 17, 13, 17, 18, 17, 3, 17, 7, 13, 9, 13, 15,
					13, 11, 14, 13, 12, 8, 13, 21, 17, 20, 17,
				};
				_transitionTable = Expand("Buffalo.Core.Lexer.Configuration.AutoConfigScanner.0.table");
				_tokenTypes = new TokenType[29]
				{
					TokenType.EOF,
					TokenType.OpenBrace, // [{]
					TokenType.CloseBrace, // [}]
					TokenType.Semicolon, // [;]
					TokenType.Assign, // [=]
					TokenType.State, // [s][t][a][t][e]
					TokenType.Token, // [t][o][k][e][n]
					TokenType.Label, // [s][t]
					TokenType.Label, // [t][o][k][e]
					TokenType.Label, // [s]
					TokenType.Label, // [s][t][a][t]
					TokenType.Label, // [t]
					TokenType.Label, // [A-Z,a-r,u-z]
					TokenType.Label, // [t][o][k]
					TokenType.Label, // [s][t][a]
					TokenType.Label, // [t][o]
					TokenType.String, // ["]["]
					TokenType.BrokenString, // ["][\\]
					TokenType.BrokenString, // ["]
					TokenType.Regex, // [^][$]
					TokenType.BrokenRegex, // [^][\\]
					TokenType.BrokenRegex, // [^]
					TokenType.Comment, // [/][/]
					TokenType.Comment, // [/][*][*][/]
					TokenType.BrokenComment, // [/][*][*]
					TokenType.BrokenComment, // [/][*]
					TokenType.Whitespace, // [\t-\r, ]
					TokenType.Error, // ![\t-\r, ,",/,;,=,A-Z,^,a-{,}]
					TokenType.Error, // [/]
				};
			}

			public static TableCache Get()
			{
				TableCache result;

				lock (_weakRef)
				{
					if ((result = (TableCache)_weakRef.Target) == null)
					{
						_weakRef.Target = result = new TableCache();
					}
				}

				return result;
			}

			[DebuggerBrowsable(DebuggerBrowsableState.Never)]
			public readonly char[] _charClassificationBoundries;
			[DebuggerBrowsable(DebuggerBrowsableState.Never)]
			public readonly ushort[] _charClassification;
			[DebuggerBrowsable(DebuggerBrowsableState.Never)]
			public readonly ushort[] _transitionTable;
			[DebuggerBrowsable(DebuggerBrowsableState.Never)]
			public readonly TokenType[] _tokenTypes;

			[DebuggerBrowsable(DebuggerBrowsableState.Never)]
			static readonly WeakReference _weakRef = new WeakReference(null);
		}
	}
}
